{
 "metadata": {
  "name": "",
  "signature": "sha256:2a003c55e51acf8fd1bb9cd9506752eb829308cf20a6f79c21721b70561d156f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The [HIPPIE database][hippie] is a dataset that integrates multiple experimental PPI datasets.\n",
      "For a given protein interaction it can produce a confidence value that the interaction exists.\n",
      "Unfortunately, it is important to note a concern with using this is that the gold standard dataset currently chosen to use in this project _is integrated into the HIPPIE dataset_.\n",
      "This could mean that the classifier can simply rely on this feature to predict the training or test set 100%.\n",
      "\n",
      "In this case the solution is simply to threshold the HIPPIE dataset at a high confidence value and use it as the gold standard dataset instead.\n",
      "This might be a good idea regardless of the results of the test.\n",
      "\n",
      "The aim of this notebook is to:\n",
      "\n",
      "1. Create a file containing the HIPPIE confidence values for each protein pair in our gold standard dataset and active zone network.\n",
      "2. See if the predictions of the HIPPIE dataset are the same as the DIP results.\n",
      "\n",
      "## Reformatting the lists\n",
      "\n",
      "The complete list is spread among a few different files.\n",
      "These files need to be reformatted to be entered into [HIPPIE's web service][hippieservice].\n",
      "First, we need to strip the zeros and ones from the two gold standard training files:\n",
      "\n",
      "1. `training.negative.Entrez.txt`\n",
      "2. `training.positive.Entrez.txt`\n",
      "\n",
      "The new files will be called:\n",
      "\n",
      "1. `training.nolabel.negative.Entrez.txt`\n",
      "2. `training.nolabel.positive.Entrez.txt`\n",
      "\n",
      "[hippie]: http://cbdm.mdc-berlin.de/tools/hippie/index.php\n",
      "[hippieservice]: http://cbdm.mdc-berlin.de/tools/hippie/network.php"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/DIP/human/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/DIP/human\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[40m\u001b[m\u001b[00mDIPtouniprot.tab\u001b[0m  \u001b[40m\u001b[m\u001b[00mflat.Entrez.txt\u001b[0m   \u001b[40m\u001b[m\u001b[00mHsapi20140427.txt\u001b[0m    \u001b[40m\u001b[m\u001b[00minteracting.Entrez.txt\u001b[0m   \u001b[40m\u001b[m\u001b[00mtraining.negative.Entrez.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00muniprottoEntrez.tab\u001b[0m\r\n",
        "\u001b[40m\u001b[m\u001b[00mflat.DIP.txt\u001b[0m      \u001b[40m\u001b[m\u001b[00mflat.uniprot.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00minteracting.DIP.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00minteracting.uniprot.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00mtraining.positive.Entrez.txt\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = csv.reader(open(\"training.negative.Entrez.txt\"), delimiter=\"\\t\")\n",
      "wc = csv.writer(open(\"training.nolabel.negative.Entrez.txt\", \"w\"), delimiter=\"\\t\")\n",
      "for line in rc:\n",
      "    line = (line[0],line[1])\n",
      "    wc.writerow(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = csv.reader(open(\"training.positive.Entrez.txt\"), delimiter=\"\\t\")\n",
      "wc = csv.writer(open(\"training.nolabel.positive.Entrez.txt\", \"w\"), delimiter=\"\\t\")\n",
      "for line in rc:\n",
      "    line = (line[0],line[1])\n",
      "    wc.writerow(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Bait and prey combinations\n",
      "\n",
      "All protein pairs from the bait and prey lists need to be placed in a file.\n",
      "First, load in the the bait and prey Entrez identifiers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/forGAVIN/pulldown_data/BAITS/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/forGAVIN/pulldown_data/BAITS\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[40m\u001b[m\u001b[00mbaitDIPcrossover.Entrez.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00mbaits.csv\u001b[0m  \u001b[40m\u001b[m\u001b[00mbaits_entrez_ids_ActiveZone.csv\u001b[0m  \u001b[40m\u001b[m\u001b[00mbaits_entrez_ids.csv\u001b[0m  \u001b[40m\u001b[m\u001b[00mensembl_bait_human_ids.csv\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baitids = list(flatten(csv.reader(open(\"baits_entrez_ids.csv\"))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/forGAVIN/pulldown_data/PREYS/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/forGAVIN/pulldown_data/PREYS\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preyids = list(flatten(csv.reader(open(\"prey_entrez_ids.csv\"))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#combine these lists\n",
      "pulldownids = baitids + preyids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point we have a list `pulldownids` of Entrez IDs for all proteins found in the pulldown experiments.\n",
      "\n",
      "We can now use that list to build a set of all possible combinations using `itertools`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#initialise list\n",
      "pulldowncomb = []\n",
      "#iterate over all possible combinations, adding to the list\n",
      "for pair in itertools.combinations(pulldownids,2):\n",
      "    pulldowncomb.append(frozenset(pair))\n",
      "#convert list to set\n",
      "pulldowncomb = set(pulldowncombb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### How many combinations are there?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Number of combinations of pulldown protein IDs: %i\"%(len(pulldowncomb))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of combinations of pulldown protein IDs: 1699335\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Saving this set to a file.\n",
      "The file will be named `pulldown.combinations.Entrez.txt`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csv.writer(open(\"pulldown.combinations.Entrez.txt\", \"w\"), delimiter=\"\\t\").writerows(map(lambda x: list(x) ,list(pulldowncomb)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using HIPPIE command line tool\n",
      "\n",
      "For large sets of protein pairs, the HIPPIE web service redirects to the command line tool.\n",
      "Specifically, the readme for the tool required is [here][hippienc] and the tool can be found [here][hippiecmd].\n",
      "\n",
      "[hippieservice]: http://cbdm.mdc-berlin.de/tools/hippie/network.php\n",
      "[hippienc]: http://cbdm.mdc-berlin.de/tools/hippie/NC/README.txt\n",
      "[hippiecmd]: http://cbdm.mdc-berlin.de/tools/hippie/download.php"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/HIPPIE/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/HIPPIE\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To retreive the most recent version of the HIPPIE dataset, script and readme:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "wget -q http://cbdm.mdc-berlin.de/tools/hippie/hippie_current.txt\n",
      "wget -q http://cbdm.mdc-berlin.de/tools/hippie/NC/HIPPIE_NC.jar\n",
      "wget -q http://cbdm.mdc-berlin.de/tools/hippie/NC/README.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The quick start guide gives usage for taking an input file when the hippie database is in the same directory and named `hippie_current.txt`:\n",
      "\n",
      "```\n",
      "java -jar HIPPIE_NC.jar -i=query.txt\n",
      "```\n",
      "\n",
      "We would also like to specify an output file, which is done using:\n",
      "\n",
      "```\n",
      "java -jar HIPPIE_NC.jar -i=query.txt -o=out.txt\n",
      "```\n",
      "\n",
      "Also, we should probably specify that the proteins will be given in Entrez format:\n",
      "\n",
      "```\n",
      "java -jar HIPPIE_NC.jar -i=query.txt -t=e -o=out.txt\n",
      "```\n",
      "\n",
      "There is also an option to restrict HIPPIE to the proteins that it is supplied, otherwise it searches for interactions between the proteins supplied and all the proteins it knows about. This is the _layer_ option and must be set to zero:\n",
      "\n",
      "```\n",
      "java -jar HIPPIE_NC.jar -i=query.txt -l=0 -t=e -o=out.txt\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The files which must be queried using this tool are given below:\n",
      "\n",
      "1. `training.nolabel.negative.Entrez.txt` - negative training examples from gold standard dataset.\n",
      "2. `training.nolabel.positive.Entrez.txt` - positive training examples from gold standard dataset.\n",
      "3. `pulldown.combinations.Entrez.txt` - all possible combinations of proteins from pulldown experiments.\n",
      "\n",
      "Starting with the smallest file, which is `training.nolabel.positive.Entrez.txt`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "java -jar HIPPIE_NC.jar -i=../DIP/human/training.nolabel.positive.Entrez.txt -t=e -l=0 -o=training.positive.HIPPIE.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looking at the file and checking to see if all pairs were mapped:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "head training.positive.HIPPIE.txt\n",
      "wc -l ../DIP/human/training.positive.Entrez.txt\n",
      "wc -l training.positive.HIPPIE.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t3783709\t\t7874\t0\t\t1\n",
        "GCR_HUMAN\t2908\tADA_HUMAN\t100\t0.85\texperiments:in vitro,Reconstituted Complex,pull down;pmids:9154805,16189514;sources:HPRD,BioGRID,I2D,Rual05\t0\n",
        "\t10111\t\t50484\t0\t\t1\n",
        "TP53B_HUMAN\t7158\tCDC16_HUMAN\t8881\t0.63\texperiments:affinity chromatography technology;pmids:22990118;sources:BioGRID\t0\n",
        "\t3020\t\t3021\t0\t\t1\n",
        "GRB2_HUMAN\t2885\tHSPB1_HUMAN\t3315\t0.56\texperiments:pull down;pmids:12577067;sources:IntAct\t0\n",
        "TPOR_HUMAN\t4352\tPTN11_HUMAN\t5781\t0.52\texperiments:in vivo;pmids:8541543;sources:HPRD,I2D\t0\n",
        "CAV1_HUMAN\t857\tERBB2_HUMAN\t2064\t0.55\texperiments:in vitro,in vivo;pmids:9685399;sources:HPRD,I2D\t0\n",
        "1433Z_HUMAN\t7534\tATPA_HUMAN\t498\t0.89\texperiments:in vivo,coimmunoprecipitation,gst pull down,affinity chromatography technology,pull down,tandem affinity purification;pmids:15324660,15161933,20618440;sources:HPRD,MINT,I2D,BioGRID,IntAct\t0\n",
        "PAN2_HUMAN\t9924\tRUVB2_HUMAN\t10856\t0.63\texperiments:affinity chromatography technology;pmids:23398456;sources:BioGRID\t0\n",
        "5103 ../DIP/human/training.positive.Entrez.txt\n",
        "43416 training.positive.HIPPIE.txt\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a much larger number of pairs after conversion because the HIPPIE script simply takes the proteins as a list and finds all the interactions it knows about between those proteins.\n",
      "As this includes not just the DIP dataset but also many others there is a larger number of interactions available without setting a cuttoff.\n",
      "To deal with this, we require a script to match the confidence values in the file produced with only the interacting pairs we care about."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/DIP/human/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/DIP/human\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#initialise csv reader\n",
      "c = csv.reader(open(\"training.nolabel.positive.Entrez.txt\"), delimiter=\"\\t\")\n",
      "#make dictionary using frozensets as keys:\n",
      "posids = {}\n",
      "for line in c:\n",
      "    line = frozenset(line)\n",
      "    posids[line] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/HIPPIE/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/HIPPIE\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#initialise csv reader\n",
      "c = csv.reader(open(\"training.positive.HIPPIE.txt\"), delimiter=\"\\t\")\n",
      "#make dictionary using frozensets as keys with the confidence scores as values\n",
      "hippieids = {}\n",
      "for line in c:\n",
      "    k = frozenset([line[1],line[3]])\n",
      "    hippieids[k] = line[4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "head training.positive.HIPPIE.txt\n",
      "wc -l ../DIP/human/training.positive.Entrez.txt\n",
      "wc -l training.positive.HIPPIE.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5071\t65018\t0.82\r\n",
        "29102\t1655\t0.14\r\n",
        "5914\t16475\t0\r\n",
        "6883\t6880\t0.87\r\n",
        "2099\t396442\t0\r\n",
        "8330\t27000\t0\r\n",
        "2244\t1497146\t0\r\n",
        "166379\t582\t0.63\r\n",
        "5216\t850504\t0\r\n",
        "4792\t4793\t0.94\r\n",
        "5103 ../DIP/human/training.positive.Entrez.txt\n",
        "4752 training.positive.HIPPIE.txt\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Strangely enough, we've dropped some pairs in the conversion, which doesn't make a lot of sense.\n",
      "It could be that the HIPPIE database is not up to date with the pairs that are in the DIP database.\n",
      "Or the method used to map from the DIP protein identifiers to Entrez used by HIPPIE differs from our method.\n",
      "\n",
      "Also odd is the fact that some of these protein pairs have a confidence value of zero attached to them.\n",
      "At this point it's uncertain why this might be.\n",
      "It could be that these values were known to be missing from the HIPPIE database so the HIPPIE script has labelled them zero.\n",
      "Or, it could be that the script is assigns no confidence to the evidence for these interactions from DIP.\n",
      "\n",
      "In any case, the two databases clearly do not match up exactly.\n",
      "Deciding whether to use the HIPPIE database as a gold standard instead of DIP is going to have to be discussed.\n",
      "The code will be designed such that the gold standard database can be easily switched in any case.\n",
      "\n",
      "The above code was modified and made into a simple Python script called `hippiematch.py` to use on the remaining two files.\n",
      "So repeating the above for the final two files can be done as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "python2 ../opencast-bio/scripts/hippiematch.py -h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Usage: python2 hippiematch.py hippiefile pairfile outputfile\n",
        "Where: \n",
        "    hippiefile is the out of the HIPPIE script\n",
        "    pairfile is the file of protein pairs to match\n",
        "    outputfile is the name of the file to output to\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "java -jar HIPPIE_NC.jar -i=../DIP/human/training.nolabel.negative.Entrez.txt -t=e -l=0 -o=training.negative.HIPPIE.txt\n",
      "python2 ../opencast-bio/scripts/hippiematch.py training.negative.HIPPIE.txt ../DIP/human/training.nolabel.negative.Entrez.txt training.negative.HIPPIE.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3060531 of 3060684 pairs matched.\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "java -jar HIPPIE_NC.jar -i=../forGAVIN/pulldown_data/PREYS/pulldown.combinations.Entrez.txt -t=e -l=0 -o=pulldown.combinations.HIPPIE.txt\n",
      "python2 ../opencast-bio/scripts/hippiematch.py pulldown.combinations.HIPPIE.txt ../forGAVIN/pulldown_data/PREYS/pulldown.combinations.Entrez.txt pulldown.combinations.HIPPIE.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1698968 of 1699335 pairs matched.\n"
       ]
      }
     ],
     "prompt_number": 74
    }
   ],
   "metadata": {}
  }
 ]
}