{
 "metadata": {
  "name": "",
  "signature": "sha256:b73a12469dd0ad8e1648e1d8d74cb0b25323b14b7444eccee78d2d233d70c9d5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generating the training and test set involves using the `ocbio.extract` module with the chosen gold standard positive and negative datasets.\n",
      "This notebook is supposed to act like a script to do this, with documentation inline.\n",
      "\n",
      "First, the datasource table must be regenerated at the _top directory_ containing the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../../"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/data/opencast/MRes\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As the data repository has now been annexed the datasource table must first be unlocked:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!git annex unlock datasource.tab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this script should be updated to add new features when available\n",
      "f = open(\"datasource.tab\", \"w\")\n",
      "c = csv.writer(f,delimiter=\"\\t\")\n",
      "# the HIPPIE feature\n",
      "c.writerow([\"HIPPIE/hippie_current.txt\",\"HIPPIE/feature.HIPPIE.db\",\n",
      "            \"protindexes=(1,3);valindexes=(4);zeromissing=1\"])\n",
      "# the abundance feature\n",
      "c.writerow([\"forGAVIN/pulldown_data/dataset/ppi_ab_entrez.csv\",\n",
      "        \"forGAVIN/pulldown_data/dataset/abundance.Entrez.db\",\n",
      "        \"ignoreheader=1;zeromissinginternal=1;fillmissing=forGAVIN/pulldown_data/dataset/abundance.average.pickle\"])\n",
      "# the affinity feature\n",
      "c.writerow([\"affinityresults/results2/unique_data_ppi_coor_C2S_entrez.csv\",\n",
      "        \"affinityresults/results2/affinity.Entrez.db\",\n",
      "        \"zeromissinginternal=1;fillmissing=affinityresults/results2/affinity.pulldown.average.pickle\"])\n",
      "# Gene Ontology features\n",
      "c.writerow([\"Gene_Ontology\",\"Gene_Ontology\",\"generator=geneontology/testgen.pickle\"])\n",
      "# Y2H SVM feature\n",
      "c.writerow([\"Y2H/Y2H.txt\",\"Y2H/Y2H.db\",\"valindexes=(4);ignoreheader=1;zeromissing=1\"])\n",
      "# ENTS feature\n",
      "c.writerow([\"ENTS\",\"ENTS\",\"generator=ents/human.ENTS.features.pickle\"])\n",
      "# iRefIndex features\n",
      "c.writerow([\"iRefIndex\",\"iRefIndex\",\"generator=iRefIndex/human.iRefIndex.Entrez.1ofk.pickle\"])\n",
      "# STRING features\n",
      "c.writerow([\"STRING\",\"STRING\",\"generator=string/human.Entrez.string.pickle\"])\n",
      "# ENTS summary feature\n",
      "c.writerow([\"ENTS_summary\",\"ENTS_summary\",\"generator=ents/human.Entrez.ENTS.summary.pickle\"])\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Importing ocbio.extract\n",
      "\n",
      "Next, `ocbio.extract` must be added to the path and imported:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.path.append(\"opencast-bio/\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ocbio.extract"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(ocbio.extract)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<module 'ocbio.extract' from 'opencast-bio/ocbio/extract.pyc'>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Unlocking databases\n",
      "\n",
      "Now that the data directory has been [annexed][gitannex] the database files must first be unlocked:\n",
      "\n",
      "[gitannex]: https://git-annex.branchable.com/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!git annex unlock Y2H/Y2H.db"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "unlock Y2H/Y2H.db (copying...) "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ok\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!git annex unlock affinityresults/results2/affinity.Entrez.db"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!git annex unlock forGAVIN/pulldown_data/dataset/abundance.Entrez.db"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!git annex unlock HIPPIE/feature.HIPPIE.db"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "unlock HIPPIE/feature.HIPPIE.db (copying...) "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ok\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Initialising assembler\n",
      "\n",
      "Then an assembler object must be initialised using the data source table:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assembler = ocbio.extract.FeatureVectorAssembler(\"datasource.tab\", verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using  from top data directory datasource.tab.\n",
        "Reading data source table:\n",
        "\tData source: HIPPIE/hippie_current.txt to be processed to HIPPIE/feature.HIPPIE.db\n",
        "\tData source: forGAVIN/pulldown_data/dataset/ppi_ab_entrez.csv to be processed to forGAVIN/pulldown_data/dataset/abundance.Entrez.db\n",
        "\tData source: affinityresults/results2/unique_data_ppi_coor_C2S_entrez.csv to be processed to affinityresults/results2/affinity.Entrez.db\n",
        "\tData source: Gene_Ontology to be processed to Gene_Ontology\n",
        "\tData source: Y2H/Y2H.txt to be processed to Y2H/Y2H.db\n",
        "\tData source: ENTS to be processed to ENTS\n",
        "\tData source: iRefIndex to be processed to iRefIndex\n",
        "\tData source: STRING to be processed to STRING\n",
        "\tData source: ENTS_summary to be processed to ENTS_summary\n",
        "Initialising parsers.\n",
        "Database HIPPIE/feature.HIPPIE.db last updated 2014-06-25 12:04:07\n",
        "Database forGAVIN/pulldown_data/dataset/abundance.Entrez.db last updated 2014-06-25 12:04:08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: 'pulldown_data/dataset/abundance.average.pickle'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-13-b650d5692679>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0massembler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mocbio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFeatureVectorAssembler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datasource.tab\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/data/opencast/MRes/opencast-bio/ocbio/extract.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sourcetab, verbose)\u001b[0m\n\u001b[0;32m     90\u001b[0m                                                      \u001b[0mparser\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"output path\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                                                      \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                                                      **parser[\"options\"]))\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;31m# have to initialise mcount here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/data/opencast/MRes/opencast-bio/ocbio/extract.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, datadir, outdir, protindexes, valindexes, script, csvdelim, ignoreheader, generator, verbose, zeromissing, zeromissinginternal, interpolator, interpolatordata, fillmissing)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfillmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[1;31m#load it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfillmissing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'pulldown_data/dataset/abundance.average.pickle'"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Regenerating features\n",
      "\n",
      "Then all the features should be regenerated to ensure they are up to date:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assembler.regenerate(verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Regenerating parsers:\n",
        "\t parser 0\n",
        "Database HIPPIE/feature.HIPPIE.db last updated 2014-06-25 12:04:07"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t parser 1\n",
        "Database forGAVIN/pulldown_data/dataset/abundance.Entrez.db last updated 2014-06-25 12:04:08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t parser 2\n",
        "Database affinityresults/results2/affinity.Entrez.db last updated 2014-06-25 12:06:47\n",
        "\t parser 3\n",
        "Custom generator function, no database to regenerate.\n",
        "\t parser 4\n",
        "Database Y2H/Y2H.db last updated 2014-06-25 12:15:04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t parser 5\n",
        "Custom generator function, no database to regenerate.\n",
        "\t parser 6\n",
        "Custom generator function, no database to regenerate.\n",
        "\t parser 7\n",
        "Custom generator function, no database to regenerate.\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Writing DIP training set\n",
      "\n",
      "Then the assemble command can be used with the two DIP gold standard flat files:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!git annex unlock features/training.nolabel.positive.Entrez.vectors.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assembler.assemble(\"DIP/human/training.nolabel.positive.Entrez.txt\",\n",
      "                   \"features/training.nolabel.positive.Entrez.vectors.txt\", verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading pairfile: DIP/human/training.nolabel.positive.Entrez.txt\n",
        "Checking feature sizes:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "global name 'zeromissing' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-15-500b7893feed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m assembler.assemble(\"DIP/human/training.nolabel.positive.Entrez.txt\",\n\u001b[1;32m----> 2\u001b[1;33m                    \"features/training.nolabel.positive.Entrez.vectors.txt\", verbose=True)\n\u001b[0m",
        "\u001b[1;32m/home/gavin/Documents/MRes/opencast-bio/ocbio/extract.pyc\u001b[0m in \u001b[0;36massemble\u001b[1;34m(self, pairfile, outputfile, pairlabels, delim, missinglabel, verbose)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                     \u001b[0mexamplefeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[1;31m#keep trying\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/gavin/Documents/MRes/opencast-bio/ocbio/extract.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m                 \u001b[1;31m#catch the key error and check if this should be zeroed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mzeromissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m                     \u001b[0mfeaturelen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalindexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfeaturelen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: global name 'zeromissing' is not defined"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!git annex unlock features/training.nolabel.negative.Entrez.vectors.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assembler.assemble(\"DIP/human/training.nolabel.negative.Entrez.txt\",\n",
      "                   \"features/training.nolabel.negative.Entrez.vectors.txt\", verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading pairfile: DIP/human/training.nolabel.negative.Entrez.txt\n",
        "Checking feature sizes:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source HIPPIE/hippie_current.txt produces features of size 1."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source forGAVIN/pulldown_data/dataset/ppi_ab_entrez.csv produces features of size 1."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source affinityresults/results2/unique_data_ppi_coor_C2S_entrez.csv produces features of size 1."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source Gene_Ontology produces features of size 90."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source Y2H/Y2H.txt produces features of size 1."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source ENTS produces features of size 104."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source iRefIndex produces features of size 11."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source STRING produces features of size 8."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Writing feature vectors."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wrote 3061800 vectors.\n",
        "Matched 0.69 % of protein pairs in DIP/human/training.nolabel.negative.Entrez.txt to features from HIPPIE/hippie_current.txt\n",
        "Matched 0.02 % of protein pairs in DIP/human/training.nolabel.negative.Entrez.txt to features from forGAVIN/pulldown_data/dataset/ppi_ab_entrez.csv\n",
        "Matched 2.24 % of protein pairs in DIP/human/training.nolabel.negative.Entrez.txt to features from affinityresults/results2/unique_data_ppi_coor_C2S_entrez.csv\n",
        "Matched 100.00 % of protein pairs in DIP/human/training.nolabel.negative.Entrez.txt to features from Gene_Ontology\n",
        "Matched 0.03 % of protein pairs in DIP/human/training.nolabel.negative.Entrez.txt to features from Y2H/Y2H.txt\n",
        "Matched 22.31 % of protein pairs in DIP/human/training.nolabel.negative.Entrez.txt to features from ENTS\n",
        "Matched 100.00 % of protein pairs in DIP/human/training.nolabel.negative.Entrez.txt to features from iRefIndex\n",
        "Matched 100.00 % of protein pairs in DIP/human/training.nolabel.negative.Entrez.txt to features from STRING\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Writing HIPPIE training set\n",
      "\n",
      "We are also planning to build a model using HIPPIE as the training set.\n",
      "To do this we will have to write corresponding feature vectors for each protein pair in the HIPPIE database.\n",
      "The HIPPIE feature must be removed from the assembler first, though."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print assem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assembler.assemble(\"HIPPIE/hippie_current.pairs.txt\",\n",
      "                   \"features/training.HIPPIE.positive.Entrez.vectors.txt\", verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The number of negative interactions required for this number of positive interactions is..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Writing Pulldown feature vectors\n",
      "\n",
      "These feature vectors correspond to all possible protein pairs involved in the pulldown experiment:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assembler.assemble(\"forGAVIN/pulldown_data/pulldown.interactions.Entrez.tsv\",\n",
      "                   \"features/pulldown.nolabel.Entrez.vectors.txt\", verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading pairfile: forGAVIN/pulldown_data/pulldown.interactions.Entrez.tsv\n",
        "Checking feature sizes:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source HIPPIE/hippie_current.txt produces features of size 1."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source forGAVIN/pulldown_data/dataset/ppi_ab_entrez.csv produces features of size 1."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source affinityresults/results2/unique_data_ppi_coor_C2S_entrez.csv produces features of size 1."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source Gene_Ontology produces features of size 90."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source Y2H/Y2H.txt produces features of size 1."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source ENTS produces features of size 104."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source iRefIndex produces features of size 11."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t Data source STRING produces features of size 8."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Writing feature vectors."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wrote 1699246 vectors.\n",
        "Matched 0.78 % of protein pairs in forGAVIN/pulldown_data/pulldown.interactions.Entrez.tsv to features from HIPPIE/hippie_current.txt\n",
        "Matched 0.94 % of protein pairs in forGAVIN/pulldown_data/pulldown.interactions.Entrez.tsv to features from forGAVIN/pulldown_data/dataset/ppi_ab_entrez.csv\n",
        "Matched 92.24 % of protein pairs in forGAVIN/pulldown_data/pulldown.interactions.Entrez.tsv to features from affinityresults/results2/unique_data_ppi_coor_C2S_entrez.csv\n",
        "Matched 100.00 % of protein pairs in forGAVIN/pulldown_data/pulldown.interactions.Entrez.tsv to features from Gene_Ontology\n",
        "Matched 0.11 % of protein pairs in forGAVIN/pulldown_data/pulldown.interactions.Entrez.tsv to features from Y2H/Y2H.txt\n",
        "Matched 31.55 % of protein pairs in forGAVIN/pulldown_data/pulldown.interactions.Entrez.tsv to features from ENTS\n",
        "Matched 100.00 % of protein pairs in forGAVIN/pulldown_data/pulldown.interactions.Entrez.tsv to features from iRefIndex\n",
        "Matched 100.00 % of protein pairs in forGAVIN/pulldown_data/pulldown.interactions.Entrez.tsv to features from STRING\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assembler.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}