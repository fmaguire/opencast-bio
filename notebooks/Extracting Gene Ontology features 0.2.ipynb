{
 "metadata": {
  "name": "",
  "signature": "sha256:7801000ca6a5ef2d37668efd24acc25a94f8eb4c158f10d2d4abfdd124918d47"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The steps involved in extracting usable features are:\n",
      "\n",
      "1. Retrieving Gene Ontology annotations for each Entrez IDs\n",
      "2. Comparing matches for all possible protein pairs\n",
      "\n",
      "## Retrieving Gene Ontology annotations for each Entrez ID\n",
      "\n",
      "To do this we must:\n",
      "\n",
      "1. Map the Entrez IDs onto corresponding Gene Ontology IDs\n",
      "2. Use [goatools][] to retrieve GO terms from `gene_ontology.1_2.obo`\n",
      "3. Add these to a dictionary using the Entrez IDs as keys with dictionaries for each term\n",
      "\n",
      "Alternatively, it looks like these terms are in the `gene2go` file retreived from the [ncbi ftp site][gene2], meaning that we wouldn't need to use [goatools][]:\n",
      "\n",
      "[goatools]: https://github.com/tanghaibao/goatools/#find-go-enrichment-of-genes-under-study\n",
      "[gene2]: ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../../geneconversion/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/geneconversion\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head gene2go"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#Format: tax_id GeneID GO_ID Evidence Qualifier GO_term PubMed Category (tab is used as a separator, pound sign - start of a comment)\r\n",
        "3702\t814629\tGO:0005634\tISM\t-\tnucleus\t-\tComponent\r\n",
        "3702\t814629\tGO:0008150\tND\t-\tbiological_process\t-\tProcess\r\n",
        "3702\t814630\tGO:0003700\tISS\t-\tsequence-specific DNA binding transcription factor activity\t11118137\tFunction\r\n",
        "3702\t814630\tGO:0005634\tISM\t-\tnucleus\t-\tComponent\r\n",
        "3702\t814630\tGO:0006355\tTAS\t-\tregulation of transcription, DNA-templated\t11118137\tProcess\r\n",
        "3702\t814630\tGO:0006499\tRCA\t-\tN-terminal protein myristoylation\t-\tProcess\r\n",
        "3702\t814630\tGO:0006635\tRCA\t-\tfatty acid beta-oxidation\t-\tProcess\r\n",
        "3702\t814630\tGO:0006891\tRCA\t-\tintra-Golgi vesicle-mediated transport\t-\tProcess\r\n",
        "3702\t814630\tGO:0016558\tRCA\t-\tprotein import into peroxisome matrix\t-\tProcess\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, it's not certain and goatools seems to produce fairly good results, so using that for now:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = csv.reader(open(\"gene2go\"), delimiter=\"\\t\")\n",
      "#skip first line\n",
      "c.next()\n",
      "#initialise dictionary\n",
      "goEntrezdict = {}\n",
      "for line in c:\n",
      "    #on every line use the Entrez ID as a key and initialise a dictionary\n",
      "    goEntrezdict[line[1]] = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then iterating through the file again we can add entries to this dictionary, each of which is a dictionary containing empty lists indexed by GO IDs:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = csv.reader(open(\"gene2go\"), delimiter=\"\\t\")\n",
      "c.next()\n",
      "for line in c:\n",
      "    goEntrezdict[line[1]][line[2]] = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Retrieving GO terms with goatools\n",
      "\n",
      "Next we use goatools, along with the Gene Ontology flat database file `gene_ontology.1_2.obo`.\n",
      "Iterating through the Entrez IDs we have found and then iterating over the GO IDs which they refer to:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../geneontology/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/geneontology\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import goatools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parsedobo = goatools.obo_parser.GODag('gene_ontology.1_2.obo')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "load obo file gene_ontology.1_2.obo\n",
        "42995"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " nodes imported\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for EntrezID in goEntrezdict.keys():\n",
      "    for goID in goEntrezdict[EntrezID].keys():\n",
      "        goEntrezdict[EntrezID][goID] = parsedobo[goID].name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looking at an example entry:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print goEntrezdict[goEntrezdict.keys()[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'GO:0016021': 'integral component of membrane'}\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Looking at crossover\n",
      "\n",
      "We are looking for annotations that will cross over between pairs of proteins.\n",
      "To do this we need to pick a number of annotations we can test each pair of Entrez IDs for.\n",
      "These should be annotations that are likely to occur in pairs, any annotations that occur in isolation in our set will be useless.\n",
      "\n",
      "So we have to count all the occurrences of every term in our dictionary of dictionaries.\n",
      "Start by flattening the list:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gotermlist = []\n",
      "for EntrezID in goEntrezdict.keys():\n",
      "    for goID in goEntrezdict[EntrezID].keys():\n",
      "        gotermlist.append(goEntrezdict[EntrezID][goID])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then count duplicates in the list using a dictionary:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dupdict = {}\n",
      "#initialise counters\n",
      "for k in gotermlist:\n",
      "    dupdict[k] = 0\n",
      "#count\n",
      "for k in gotermlist:\n",
      "    dupdict[k] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import heapq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#find term that is repeated most often\n",
      "print \"Terms that occurred most often:\"\n",
      "for k in heapq.nlargest(10, dupdict, key=lambda x: dupdict[x]):\n",
      "    print \"\\t\"+\"%s occurred %i times\"%(k,dupdict[k])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Terms that occurred most often:\n",
        "\tmolecular_function occurred 52423 times\n",
        "\tbiological_process occurred 49804 times\n",
        "\tcellular_component occurred 38992 times\n",
        "\tnucleus occurred 38516 times\n",
        "\tcytoplasm occurred 28668 times\n",
        "\tintegral component of membrane occurred 25343 times\n",
        "\tmembrane occurred 21333 times\n",
        "\tplasma membrane occurred 18145 times\n",
        "\tprotein binding occurred 15731 times\n",
        "\tmitochondrion occurred 12599 times\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The three most common terms are __not terms__, they are domains.\n",
      "There must be a problem with goatools, or a problem with the database file.\n",
      "The rest of the most common terms are all localisations."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Splitting by domain\n",
      "\n",
      "There are [three domains][gohelp] in the Gene Ontology database.\n",
      "We could split the above to count within each of these quite easily.\n",
      "This was also done by [Qi][qiweb] when using the Gene Ontology as features.\n",
      "\n",
      "Repeating the above for each domain:\n",
      "\n",
      "[gohelp]: http://www.geneontology.org/GO.doc.shtml\n",
      "[qiweb]: http://www.cs.cmu.edu/%7Eqyj/papers_sulp/proteins05_pages/features.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../geneconversion/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/geneconversion\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = csv.reader(open(\"gene2go\"), delimiter=\"\\t\")\n",
      "c.next()\n",
      "for line in c:\n",
      "    goEntrezdict[line[1]][line[2]] = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for EntrezID in goEntrezdict.keys():\n",
      "    for goID in goEntrezdict[EntrezID].keys():\n",
      "        goEntrezdict[EntrezID][goID][parsedobo[goID].namespace] = parsedobo[goID].name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print goEntrezdict[goEntrezdict.keys()[4]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'GO:0005575': {'cellular_component': 'cellular_component'}, 'GO:0045596': {'biological_process': 'negative regulation of cell differentiation'}, 'GO:0000332': {'molecular_function': 'template for synthesis of G-rich strand of telomere DNA activity'}, 'GO:0007004': {'biological_process': 'telomere maintenance via telomerase'}}\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gotermdict = {}\n",
      "#initialise dictionaries\n",
      "for EntrezID in goEntrezdict.keys():\n",
      "    for goID in goEntrezdict[EntrezID].keys():\n",
      "        for domain in goEntrezdict[EntrezID][goID].keys():\n",
      "            gotermdict[domain] = {}\n",
      "#initialise counters in dictionaries\n",
      "for EntrezID in goEntrezdict.keys():\n",
      "    for goID in goEntrezdict[EntrezID].keys():\n",
      "        for domain in goEntrezdict[EntrezID][goID].keys():\n",
      "            term = goEntrezdict[EntrezID][goID][domain]\n",
      "            gotermdict[domain][term] = 0\n",
      "#count\n",
      "for EntrezID in goEntrezdict.keys():\n",
      "    for goID in goEntrezdict[EntrezID].keys():\n",
      "        for domain in goEntrezdict[EntrezID][goID].keys():\n",
      "            term = goEntrezdict[EntrezID][goID][domain]\n",
      "            gotermdict[domain][term] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k in gotermdict.keys():\n",
      "    print \"Domain %s:\"%k\n",
      "    for ke in heapq.nlargest(10, gotermdict[k], key=lambda x: gotermdict[k][x]):\n",
      "        print \"\\t\"+\"%s occurred %i times\"%(ke,gotermdict[k][ke])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Domain molecular_function:\n",
        "\tmolecular_function occurred 52423 times\n",
        "\tprotein binding occurred 15731 times\n",
        "\tmetal ion binding occurred 12410 times\n",
        "\tATP binding occurred 10840 times\n",
        "\tDNA binding occurred 10210 times\n",
        "\tzinc ion binding occurred 8135 times\n",
        "\tnucleotide binding occurred 7783 times\n",
        "\tsequence-specific DNA binding transcription factor activity occurred 7446 times\n",
        "\thydrolase activity occurred 5134 times\n",
        "\tG-protein coupled receptor activity occurred 4838 times\n",
        "Domain cellular_component:\n",
        "\tcellular_component occurred 38992 times\n",
        "\tnucleus occurred 38516 times\n",
        "\tcytoplasm occurred 28668 times\n",
        "\tintegral component of membrane occurred 25343 times\n",
        "\tmembrane occurred 21333 times\n",
        "\tplasma membrane occurred 18145 times\n",
        "\tmitochondrion occurred 12599 times\n",
        "\tcytosol occurred 11760 times\n",
        "\textracellular region occurred 8696 times\n",
        "\textracellular vesicular exosome occurred 6349 times\n",
        "Domain biological_process:\n",
        "\tbiological_process occurred 49804 times\n",
        "\tregulation of transcription, DNA-templated occurred 10962 times\n",
        "\ttranscription, DNA-templated occurred 7165 times\n",
        "\tmetabolic process occurred 7122 times\n",
        "\ttransport occurred 6638 times\n",
        "\tsignal transduction occurred 6188 times\n",
        "\tG-protein coupled receptor signaling pathway occurred 6024 times\n",
        "\toxidation-reduction process occurred 5158 times\n",
        "\tproteolysis occurred 4574 times\n",
        "\ttranslation occurred 4021 times\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Bait and Prey\n",
      "\n",
      "The question is, which terms should we pick to be effective features?\n",
      "Obviously we want ones with a lot of crossover so there'll actually be something happening.\n",
      "But, we also want to make sure they'll be useful on the proteins we're actually going to use the classifier on at some point.\n",
      "The terms with the largest crossover on the the bait and prey proteins from crossover experiments, taking from all three domains, would probably be the best choice.\n",
      "\n",
      "Retreiving the bait and prey protein list and building this list of terms to match:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../forGAVIN/pulldown_data/BAITS/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/forGAVIN/pulldown_data/BAITS\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baitids = list(flatten(csv.reader(open(\"baits_entrez_ids.csv\"), delimiter=\"\\t\")))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../PREYS/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/forGAVIN/pulldown_data/PREYS\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preyids = list(flatten(csv.reader(open(\"prey_entrez_ids.csv\"), delimiter=\"\\t\")))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../../../geneconversion/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/geneconversion\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initialising new dictionary for just these Entrez IDs:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baitpreyEntrezdict = {}\n",
      "#initialise dictionaries in this dictionary\n",
      "for i in baitids+preyids:\n",
      "    baitpreyEntrezdict[i] = {}\n",
      "#iterate through gene2go file\n",
      "c = csv.reader(open(\"gene2go\"), delimiter=\"\\t\")\n",
      "#skip first line\n",
      "c.next()\n",
      "for line in c:\n",
      "    try:\n",
      "        baitpreyEntrezdict[line[1]][line[2]] = {}\n",
      "    except KeyError:\n",
      "        #ignore Entrez IDs that don't match\n",
      "        pass\n",
      "#use goatools to retrieve domains and terms using IDs\n",
      "#building dictionary with domains as keys this time\n",
      "for entrezID in baitpreyEntrezdict.keys():\n",
      "    goIDs = baitpreyEntrezdict[entrezID].keys()\n",
      "    #reinitialise the dictionary\n",
      "    baitpreyEntrezdict[entrezID] = {}\n",
      "    for goID in goIDs:\n",
      "        baitpreyEntrezdict[entrezID][parsedobo[goID].namespace] = []\n",
      "    for goID in goIDs:\n",
      "        baitpreyEntrezdict[entrezID][parsedobo[goID].namespace].append(parsedobo[goID].name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print baitpreyEntrezdict[baitpreyEntrezdict.keys()[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'molecular_function': ['phosphoprotein binding'], 'cellular_component': ['growth cone', 'plasma membrane'], 'biological_process': ['neuron projection development']}\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "domains = ['molecular_function','cellular_component','biological_process']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#iterate over domains and count the occurence of terms:\n",
      "gotermdict = {}\n",
      "for domain in domains:\n",
      "    gotermdict[domain] = {}\n",
      "#initialise counters\n",
      "for entrezID in baitpreyEntrezdict.keys():\n",
      "    for domain in baitpreyEntrezdict[entrezID].keys():\n",
      "        for term in baitpreyEntrezdict[entrezID][domain]:\n",
      "            gotermdict[domain][term] = 0\n",
      "#count\n",
      "for entrezID in baitpreyEntrezdict.keys():\n",
      "    for domain in baitpreyEntrezdict[entrezID].keys():\n",
      "        for term in baitpreyEntrezdict[entrezID][domain]:\n",
      "            gotermdict[domain][term] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k in gotermdict.keys():\n",
      "    print \"Domain %s:\"%k\n",
      "    for ke in heapq.nlargest(10, gotermdict[k], key=lambda x: gotermdict[k][x]):\n",
      "        print \"\\t\"+\"%s occurred %i times\"%(ke,gotermdict[k][ke])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Domain molecular_function:\n",
        "\tprotein binding occurred 960 times\n",
        "\tpoly(A) RNA binding occurred 308 times\n",
        "\tATP binding occurred 232 times\n",
        "\tmetal ion binding occurred 137 times\n",
        "\tidentical protein binding occurred 100 times\n",
        "\tRNA binding occurred 99 times\n",
        "\tprotein homodimerization activity occurred 97 times\n",
        "\tcalcium ion binding occurred 88 times\n",
        "\tzinc ion binding occurred 79 times\n",
        "\tGTP binding occurred 78 times\n",
        "Domain cellular_component:\n",
        "\tcytoplasm occurred 614 times\n",
        "\tcytosol occurred 575 times\n",
        "\tnucleus occurred 554 times\n",
        "\textracellular vesicular exosome occurred 550 times\n",
        "\tplasma membrane occurred 449 times\n",
        "\tmitochondrion occurred 265 times\n",
        "\tintegral component of membrane occurred 252 times\n",
        "\tnucleolus occurred 235 times\n",
        "\tnucleoplasm occurred 143 times\n",
        "\tmembrane occurred 130 times\n",
        "Domain biological_process:\n",
        "\tsmall molecule metabolic process occurred 266 times\n",
        "\tgene expression occurred 184 times\n",
        "\tviral process occurred 144 times\n",
        "\tsignal transduction occurred 130 times\n",
        "\tcellular protein metabolic process occurred 125 times\n",
        "\tsynaptic transmission occurred 114 times\n",
        "\tRNA metabolic process occurred 104 times\n",
        "\tmRNA metabolic process occurred 99 times\n",
        "\ttransmembrane transport occurred 98 times\n",
        "\tblood coagulation occurred 97 times\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Saving the 30 most common of each of these domains to a file in the geneontology directory:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../geneontology/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/geneontology\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k in gotermdict.keys():\n",
      "    f = open(\"%s.baitprey.term\"%k, \"w\")\n",
      "    for ke in heapq.nlargest(30, gotermdict[k], key=lambda x: gotermdict[k][x]):\n",
      "        f.write(\"%i\"%gotermdict[k][ke]+\"\\n\")\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[40m\u001b[m\u001b[00mbiological_process.baitprey.term\u001b[0m  \u001b[40m\u001b[m\u001b[00mcellular_component.baitprey.term\u001b[0m  \u001b[40m\u001b[m\u001b[00mgene_association.goa_human\u001b[0m  \u001b[40m\u001b[m\u001b[00mgene_ontology.1_2.obo\u001b[0m  \u001b[40m\u001b[m\u001b[00mgeneontology.flat.pairs.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00mgoa.README\u001b[0m  \u001b[40m\u001b[m\u001b[00mmolecular_function.baitprey.term\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Building feature table and database\n",
      "\n",
      "We intend to produce a files of the following form which can be used in conjunction with the `ocbio.extract` module:\n",
      "\n",
      "| Protein 1 | Protein 2 | GO molecular function feature 1 | ... | GO biological process feature 90 |\n",
      "| --------- | --------- | ----------------------- | --- | ------------------------ |\n",
      "| 1234      | 3214      | 0                       | ... | 1                        |\n",
      "| ...       | ...       | ...                     | ... | ...                      |\n",
      "\n",
      "Where a 1 is placed in an entry if both proteins share that Gene Ontology term, otherwise it is zero.\n",
      "To build this file we must iterate through all combinations of all the Entrez identifiers in the `gene2go` file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../geneconversion/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/geneconversion\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read through this file and make a list of GO IDs for the example gene chosen above\n",
      "c = csv.reader(open(\"gene2go\"), delimiter=\"\\t\")\n",
      "c.next()\n",
      "#take second column and make it a set\n",
      "EntrezIDs = []\n",
      "for line in c:\n",
      "    #only human IDs\n",
      "    if line[0] == \"9606\":\n",
      "        EntrezIDs.append(line[1])\n",
      "EntrezIDs = set(EntrezIDs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#build a dictionary as above for this list of Entrez IDs\n",
      "goEntrezdict = {}\n",
      "for i in EntrezIDs:\n",
      "    goEntrezdict[i] = {}\n",
      "#iterate through gene2go file\n",
      "c = csv.reader(open(\"gene2go\"), delimiter=\"\\t\")\n",
      "#skip first line\n",
      "c.next()\n",
      "for line in c:\n",
      "    try:\n",
      "        goEntrezdict[line[1]][line[2]] = {}\n",
      "    except KeyError:\n",
      "        #ignore Entrez IDs that don't match\n",
      "        pass\n",
      "#use goatools to retrieve domains and terms using IDs\n",
      "#building dictionary with domains as keys this time\n",
      "for entrezID in goEntrezdict.keys():\n",
      "    goIDs = goEntrezdict[entrezID].keys()\n",
      "    #reinitialise the dictionary\n",
      "    goEntrezdict[entrezID] = {}\n",
      "    for goID in goIDs:\n",
      "        goEntrezdict[entrezID][parsedobo[goID].namespace] = []\n",
      "    for goID in goIDs:\n",
      "        goEntrezdict[entrezID][parsedobo[goID].namespace].append(parsedobo[goID].name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the lists of terms we're trying to match to:\n",
      "terms = {}\n",
      "for k in gotermdict.keys():\n",
      "    terms[k] = []\n",
      "    for ke in heapq.nlargest(30, gotermdict[k], key=lambda x: gotermdict[k][x]):\n",
      "        terms[k].append(ke)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Moving to external to avoid filling up my main hard drive:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /mnt/external/remotes/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/mnt/external/remotes\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mkdir geneontology"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd geneontology/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/mnt/external/remotes/geneontology\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#write header to file\n",
      "c = csv.writer(open(\"geneontology.flat.pairs.txt\", \"w\"),delimiter=\"\\t\")\n",
      "line = [\"Protein 1\", \"Protein 2\"]\n",
      "for k in terms.keys():\n",
      "    for term in terms[k]:\n",
      "        line.append(\"%s:%s\"%(k,term))\n",
      "c.writerow(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.misc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#how long will this take?\n",
      "npairs = scipy.misc.comb(len(EntrezIDs),2)\n",
      "print \"Number of lines to write to file %i\"%npairs\n",
      "lcount = 0\n",
      "#first build vectors for each Entrez ID:\n",
      "govectordict= {}\n",
      "for entrezID in EntrezIDs:\n",
      "    vec = []\n",
      "    for domain in domains:\n",
      "        for term in terms[domain]:\n",
      "            try:\n",
      "                if term in goEntrezdict[entrezID][domain]:\n",
      "                    vec.append(1)\n",
      "                else:\n",
      "                    vec.append(0)\n",
      "            except KeyError:\n",
      "                vec.append(0)\n",
      "    #save to dictionary\n",
      "    govectordict[entrezID] = array(vec[:])\n",
      "#iterate over combinations of Entrez pairs\n",
      "for pair in itertools.combinations(EntrezIDs,2):\n",
      "    #building the line as it goes\n",
      "    line = list(pair) + list(govectordict[pair[0]]*govectordict[pair[1]])\n",
      "    if lcount%1000000 == 0:\n",
      "        print \"%.4f\"%(100.0*lcount/npairs)+\"% lines written\"\n",
      "    lcount += 1\n",
      "    #write this new line to file\n",
      "    c.writerow(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of lines to write to file 165920436\n",
        "0.0000% lines written"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Left the above script to run overnight, it produced a 14gb file which is too large to query with `wc -l` in reasonable time.\n",
      "Instead, used [this script][qwc] to find the approximate number of lines.\n",
      "Should be relatively accurate in this case as the structure of the file is quite regular:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!~/qwc.sh geneontology.flat.pairs.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "73501163 geneontology.flat.pairs.txt\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which is a little less than halfway to the full line count shown above.\n",
      "\n",
      "Alternatively, we could avoid using the flat file altogether and save it to a database immediately.\n",
      "Attempting to write such a database to see how long that will take:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.path.append(\"/home/gavin/Documents/MRes/opencast-bio/\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ocbio.extract"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#how long will this take?\n",
      "npairs = scipy.misc.comb(len(EntrezIDs),2)\n",
      "print \"Number of lines to write to file %i\"%npairs\n",
      "lcount = 0\n",
      "#first build vectors for each Entrez ID:\n",
      "govectordict= {}\n",
      "for entrezID in EntrezIDs:\n",
      "    vec = []\n",
      "    for domain in domains:\n",
      "        for term in terms[domain]:\n",
      "            try:\n",
      "                if term in goEntrezdict[entrezID][domain]:\n",
      "                    vec.append(1)\n",
      "                else:\n",
      "                    vec.append(0)\n",
      "            except KeyError:\n",
      "                vec.append(0)\n",
      "    #save to dictionary\n",
      "    govectordict[entrezID] = array(vec[:])\n",
      "#open database    \n",
      "db = ocbio.extract.openpairshelf(\"geneontology.pairs.db\")\n",
      "#iterate over combinations of Entrez pairs\n",
      "for pair in itertools.combinations(EntrezIDs,2):\n",
      "    #building the line as it goes\n",
      "    line = list(govectordict[pair[0]]*govectordict[pair[1]])\n",
      "    if lcount%100000 == 0:\n",
      "        print \"%.4f\"%(100.0*lcount/npairs)+\"% lines written\"\n",
      "    lcount += 1\n",
      "    #write this new line to database\n",
      "    db[frozenset(pair)] = line\n",
      "db.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of lines to write to file 165920436\n",
        "0.0000% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.0603% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.1205% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.1808% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.2411% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.3013% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.3616% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.4219% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.4822% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.5424% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.6027% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.6630% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.7232% lines written"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-58-560a737219f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mlcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m#write this new line to database\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mdb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfrozenset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/gavin/Documents/MRes/opencast-bio/ocbio/extract.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\t\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mshelve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDbfilenameShelf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/shelve.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Seems like the efficient way to do this would be to use a generator.\n",
      "Scikit-learn would probably support a generator.\n",
      "Interestingly, since shelve and pickle can store arbitrary Python objects there's nothing stopping me from storing the generator as an object in a pickle file.\n",
      "\n",
      "Then the final file we want to generate would be itself a generator which produces feature vectors corresponding to a list of protein pairs.\n",
      "This could be added as an option to the `ocbio.extract.ProteinParser` class, but some adjustment to the system would have to be done.\n",
      "The parsers themselves could be stored and then these used to index protein pairs.\n",
      "\n",
      "## Using a Generator\n",
      "\n",
      "To build a generator function from the above code we just need to supply variables used when writing the above file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def genGOfvector(pairs,goEntrezdict,terms):\n",
      "    '''Generator function for creating feature vectors for Gene Ontology:\n",
      "    Taking as input arguments:\n",
      "        * list of pairs of proteins to map (pairs should be frozensets)\n",
      "        * dictionary mapping from Entrez IDs to dictionary containing GO terms keyed by domain\n",
      "        * dictionary of terms we're interested in keyed by domain\n",
      "    Returns iterable sequence of corresponding feature vectors'''\n",
      "    # First define the domains, I'm guessing they're not changing\n",
      "    domains = ['molecular_function','cellular_component','biological_process']\n",
      "    # get a flattened set of Entrez IDs:\n",
      "    EntrezIDs = set(flatten(map(list,pairs)))\n",
      "    # initialise the vectors we're going to be using:\n",
      "    govectordict= {}\n",
      "    for entrezID in EntrezIDs:\n",
      "        vec = []\n",
      "        for domain in domains:\n",
      "            for term in terms[domain]:\n",
      "                try:\n",
      "                    if term in goEntrezdict[entrezID][domain]:\n",
      "                        vec.append(1)\n",
      "                    else:\n",
      "                        vec.append(0)\n",
      "                except KeyError:\n",
      "                    vec.append(0)\n",
      "        #save to dictionary\n",
      "        govectordict[entrezID] = array(vec[:])\n",
      "    #iterate over combinations of Entrez pairs\n",
      "    for pair in pairs:\n",
      "        #building the line as it goes\n",
      "        line = list(govectordict[pair[0]]*govectordict[pair[1]])\n",
      "        #yield this feature vector\n",
      "        yield line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testpairs = itertools.combinations(list(EntrezIDs)[0:10],2)\n",
      "fvectors = genGOfvector(list(testpairs),goEntrezdict,terms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open(\"testgen.pickle\",\"wb\")\n",
      "pickle.dump(fvectors,f)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "can't pickle generator objects",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-93-429889b1b145>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"testgen.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfvectors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m     \u001b[0mPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mdump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPROTO\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mchr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__reduce_ex__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m                 \u001b[0mrv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__reduce__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/copy_reg.pyc\u001b[0m in \u001b[0;36m_reduce_ex\u001b[1;34m(self, proto)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"can't pickle %s objects\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: can't pickle generator objects"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a problem and there are [two ways around it](http://stackoverflow.com/questions/7180212/why-cant-generators-be-pickled).\n",
      "Could write a pseudo-generator class, instantiate it and pickle it.\n",
      "Or, since I really only want to generate a single set of features each time could make it a function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def genGOfvector(pair,goEntrezdict,terms):\n",
      "    '''Generator function for creating feature vectors for Gene Ontology:\n",
      "    Taking as input arguments:\n",
      "        * list of pairs of proteins to map (pairs should be frozensets)\n",
      "        * dictionary mapping from Entrez IDs to dictionary containing GO terms keyed by domain\n",
      "        * dictionary of terms we're interested in keyed by domain\n",
      "    Returns iterable sequence of corresponding feature vectors'''\n",
      "    # First define the domains, I'm guessing they're not changing\n",
      "    domains = ['molecular_function','cellular_component','biological_process']\n",
      "    # initialise the vectors we're going to be using:\n",
      "    govectordict= {}\n",
      "    for entrezID in pair:\n",
      "        vec = []\n",
      "        for domain in domains:\n",
      "            for term in terms[domain]:\n",
      "                try:\n",
      "                    if term in goEntrezdict[entrezID][domain]:\n",
      "                        vec.append(1)\n",
      "                    else:\n",
      "                        vec.append(0)\n",
      "                except KeyError:\n",
      "                    vec.append(0)\n",
      "        #save to dictionary\n",
      "        govectordict[entrezID] = array(vec[:])\n",
      "    #iterate over combinations of Entrez pairs\n",
      "    #building the line as it goes\n",
      "    line = list(govectordict[pair[0]]*govectordict[pair[1]])\n",
      "    #yield this feature vector\n",
      "    return line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testpairs = itertools.combinations(list(EntrezIDs)[0:10],2)\n",
      "testpair = list(testpairs)[1]\n",
      "fvector = genGOfvector(testpair,goEntrezdict,terms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#then try to pickle this\n",
      "f = open(\"testgen.pickle\",\"wb\")\n",
      "pickle.dump(genGOfvector,f)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately, this function has no memory so we'd have to pickle the goEntrezdict and the terms separately.\n",
      "It is easier to create an object with it's own `__getitem__` method which can then be instantiated and pickled with the required data stored.\n",
      "Then this can be handed straight into the parsing code and all that's required is to make sure it has a definition of the class available."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "class GOfvectors():\n",
      "    def __init__(self,goEntrezdict,terms):\n",
      "        self.goEntrezdict = goEntrezdict\n",
      "        self.terms = terms\n",
      "        return None\n",
      "    \n",
      "    def __getitem__(self,key):\n",
      "        pair = list(key)\n",
      "        if len(pair)==1:\n",
      "            pair = pair*2\n",
      "        # First define the domains, I'm guessing they're not changing\n",
      "        domains = ['molecular_function','cellular_component','biological_process']\n",
      "        # initialise the vectors we're going to be using:\n",
      "        govectordict= {}\n",
      "        for entrezID in pair:\n",
      "            vec = []\n",
      "            for domain in domains:\n",
      "                for term in self.terms[domain]:\n",
      "                    try:\n",
      "                        if term in self.goEntrezdict[entrezID][domain]:\n",
      "                            vec.append(1)\n",
      "                        else:\n",
      "                            vec.append(0)\n",
      "                    except KeyError:\n",
      "                        vec.append(0)\n",
      "            #save to dictionary\n",
      "            govectordict[entrezID] = np.array(vec[:])\n",
      "        #iterate over combinations of Entrez pairs\n",
      "        #building the line as it goes\n",
      "        line = list(govectordict[pair[0]]*govectordict[pair[1]])\n",
      "        #yield this feature vector\n",
      "        return line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then save the above to a file in ocbio, if rerunning this __make sure the line number is correct__:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../opencast-bio/ocbio/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/opencast-bio/ocbio\n"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%save -f geneontology.py 88"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The following commands were written to file `geneontology.py`:\n",
        "import numpy as np\n",
        "\n",
        "class GOfvectors():\n",
        "    def __init__(self,goEntrezdict,terms):\n",
        "        self.goEntrezdict = goEntrezdict\n",
        "        self.terms = terms\n",
        "        return None\n",
        "    \n",
        "    def __getitem__(self,key):\n",
        "        pair = list(key)\n",
        "        if len(pair)==1:\n",
        "            pair = pair*2\n",
        "        # First define the domains, I'm guessing they're not changing\n",
        "        domains = ['molecular_function','cellular_component','biological_process']\n",
        "        # initialise the vectors we're going to be using:\n",
        "        govectordict= {}\n",
        "        for entrezID in pair:\n",
        "            vec = []\n",
        "            for domain in domains:\n",
        "                for term in self.terms[domain]:\n",
        "                    try:\n",
        "                        if term in self.goEntrezdict[entrezID][domain]:\n",
        "                            vec.append(1)\n",
        "                        else:\n",
        "                            vec.append(0)\n",
        "                    except KeyError:\n",
        "                        vec.append(0)\n",
        "            #save to dictionary\n",
        "            govectordict[entrezID] = np.array(vec[:])\n",
        "        #iterate over combinations of Entrez pairs\n",
        "        #building the line as it goes\n",
        "        line = list(govectordict[pair[0]]*govectordict[pair[1]])\n",
        "        #yield this feature vector\n",
        "        return line\n"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.path.append(\"/home/gavin/Documents/MRes/opencast-bio/\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ocbio.geneontology"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = ocbio.geneontology.GOfvectors(goEntrezdict,terms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test[testpair]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../../geneontology/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/geneontology\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pickle the instance with the data in it\n",
      "f = open(\"testgen.pickle\",\"wb\")\n",
      "pickle.dump(test,f)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print testpair"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('114787', '114785')\n"
       ]
      }
     ],
     "prompt_number": 106
    }
   ],
   "metadata": {}
  }
 ]
}