{
 "metadata": {
  "name": "",
  "signature": "sha256:c5b9cf1876af9636b513b9acf85ddb7426a09993814480d2dcd401fc9fbc9f99"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###### Gavin Gray 9th June 2014\n",
      "\n",
      "Ran into problems with code in previous notebook due to complicated way of mapping from the list of DIP entry proteins to the uniprot identifiers to the Entrez identifiers.\n",
      "Simplifying this process to avoid erroneous entries.\n",
      "Writing code to:\n",
      "\n",
      "1. Extract DIP protein identifier entries:\n",
      "    1. and their interaction relationships\n",
      "2. Convert these DIP protein identifiers to Entrez and Uniprot identifiers\n",
      "3. Link these identifiers to their sequences and NCBI database entries.\n",
      "\n",
      "## Extracting DIP protein identifiers\n",
      "\n",
      "Code from previous notebook worked fine for this, but failed to preserve information about which interactions existed.\n",
      "Making a few small changes to ensure that works."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/DIP/human/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/DIP/human\n"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[40m\u001b[m\u001b[00mDIPderived.uniprot.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00mEntrezIDs\u001b[0m        \u001b[40m\u001b[m\u001b[00mflat.uniprot.txt\u001b[0m     \u001b[40m\u001b[m\u001b[00minteracting.Entrez.txt\u001b[0m   \u001b[40m\u001b[m\u001b[00mrefseqIDs.txt\u001b[0m        \u001b[40m\u001b[m\u001b[00mtotaluniprotEntrezmap.tab\u001b[0m  \u001b[40m\u001b[m\u001b[00muniprotIDs.txt\u001b[0m              \u001b[40m\u001b[m\u001b[00muniprottoEntrez.tab\u001b[0m\r\n",
        "\u001b[40m\u001b[m\u001b[00mDIPIDs.txt\u001b[0m              \u001b[40m\u001b[m\u001b[00mflat.DIP.txt\u001b[0m     \u001b[40m\u001b[m\u001b[00mHsapi20140427.txt\u001b[0m    \u001b[40m\u001b[m\u001b[00minteracting.uniprot.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00mrefseqtouniprot.tab\u001b[0m  \u001b[40m\u001b[m\u001b[00mtotal.uniprot.txt\u001b[0m          \u001b[40m\u001b[m\u001b[00muniprotplusDIPderived.txt\u001b[0m\r\n",
        "\u001b[40m\u001b[m\u001b[00mDIPtouniprot.tab\u001b[0m        \u001b[40m\u001b[m\u001b[00mflat.Entrez.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00minteracting.DIP.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00mnorefeqoruniprot\u001b[0m         \u001b[40m\u001b[m\u001b[00mtotal.Entrez.txt\u001b[0m     \u001b[40m\u001b[m\u001b[00muniprotDIPmap.tab\u001b[0m          \u001b[40m\u001b[m\u001b[00muniprotplusDIPderived.txt~\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "c = csv.reader(open(\"Hsapi20140427.txt\"), delimiter=\"\\t\")\n",
      "#skip first line\n",
      "c.next()\n",
      "#take out the first two strings for every line\n",
      "IDstrings = map(lambda x: (x[0],x[1]), c )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# want to go through this and remove the uniprot and refseq identities\n",
      "# unfortunately, fastest way to write this is with a list comprehension\n",
      "IDstrings = [(x.split(\"|\")[0],y.split(\"|\")[0]) for (x,y) in IDstrings if \"DIP\" in x.split(\"|\")[0] and \"DIP\" in y.split(\"|\")[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import OrderedDict\n",
      "#flatten and remove duplicate entries, but keep the original structure\n",
      "flatIDstrings = list(OrderedDict.fromkeys(flatten(IDstrings)))\n",
      "print \"Number of proteins in DIP human dataset is %i\"%len(flatIDstrings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of proteins in DIP human dataset is 4026\n"
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now there are two variables in use:\n",
      "\n",
      "1. `IDstrings` - A list of pairs of interacting proteins in the DIP format.\n",
      "2. `flatIDstrings` - A list of all proteins in the above list, with redundancies removed.\n",
      "\n",
      "The next step is to convert both of these lists to Uniprot and Entrez identifiers.\n",
      "However, this is not a one to one tranformation.\n",
      "Some identifiers could map to two identifiers or none.\n",
      "This will have to be taken into account to avoid interactions between protein identifiers that don't exist.\n",
      "\n",
      "The dictionary can be built using the [Uniprot ID mapping service][uniprotidmap] with the flat file used as input.\n",
      "Doing this, we can load this file back in and create a Python dictionary from it:\n",
      "\n",
      "[uniprotidmap]: http://www.uniprot.org/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#writing the flattened protein IDs to file\n",
      "c = csv.writer(open(\"flat.DIP.txt\", \"w\"), delimiter=\"\\n\")\n",
      "c.writerow(flatIDstrings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 183
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Uniprot ID mapping service returned:\n",
      "\n",
      "> 3,509 out of 3,844 identifiers mapped to 3,467 identifiers in the target data set \n",
      "\n",
      "Reading in this file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = csv.reader(open(\"DIPtouniprot.tab\"), delimiter=\"\\t\")\n",
      "# skip first row\n",
      "c.next()\n",
      "cl = list(c)\n",
      "# build dictionary\n",
      "DIPtouni = {}\n",
      "for l in cl:\n",
      "    #place an empty list in for every DIP protein mapped\n",
      "    DIPtouni[l[0]] = []\n",
      "for l in cl:\n",
      "    #fill the lists with uniprot identifiers\n",
      "    DIPtouni[l[0]].append(l[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 184
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now can convert arbitrary DIP identifiers to uniprot:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print DIPtouni[flatIDstrings[8]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Q92793']\n"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Converting the entire set of DIP identifiers to Uniprot while:\n",
      "\n",
      "* Discarding any that don't map\n",
      "* Creating duplicate entries for those that map to multiple identifiers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "uniIDstrings = []\n",
      "faildict = {}\n",
      "for l,k in zip(IDstrings,range(len(IDstrings))):\n",
      "    # try to retreive entries for these proteins\n",
      "    try:\n",
      "        unip = map(lambda x: DIPtouni[x], l)\n",
      "        if len(unip[0]) >= 1 or len(unip[1]) >= 1:\n",
      "            #iterate over combinations of both:\n",
      "            for i in itertools.product(unip[0],unip[1]):\n",
      "                uniIDstrings.append(i)\n",
      "    except KeyError:\n",
      "        faildict[k] = l\n",
      "print \"Failed to map %i of %i entries.\"%(len(faildict.values()), len(IDstrings))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Failed to map 976 of 5951 entries.\n"
       ]
      }
     ],
     "prompt_number": 186
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The flattened list of protein identifiers must also be mapped to Uniprot, but this is simply the values contained in the dictionary used to convert from DIP to Uniprot identifiers.\n",
      "Writing these to a file these can then be used to convert to Entrez identifiers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = csv.writer(open(\"flat.uniprot.txt\", \"w\"), delimiter=\"\\n\")\n",
      "flatuniprot = list(flatten(DIPtouni.values()))\n",
      "c.writerow(flatuniprot)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using this on the Uniprot mapping service returns:\n",
      "\n",
      "> 3,325 out of 3,511 identifiers mapped to 3,437 identifiers in the target data set \n",
      "\n",
      "Can then load in the resulting table as a dictionary again, and use this to convert the uniprot list of interacting pairs:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = csv.reader(open(\"uniprottoEntrez.tab\"), delimiter=\"\\t\")\n",
      "# skip first row\n",
      "c.next()\n",
      "cl = list(c)\n",
      "# build dictionary\n",
      "unitoEnt = {}\n",
      "for l in cl:\n",
      "    unitoEnt[l[0]] = []\n",
      "for l in cl:\n",
      "    unitoEnt[l[0]].append(l[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "EntIDstrings = []\n",
      "faildictEnt = {}\n",
      "for l,k in zip(uniIDstrings,range(len(uniIDstrings))):\n",
      "    # try to retreive entries for these proteins\n",
      "    try:\n",
      "        unip = map(lambda x: unitoEnt[x], l)\n",
      "        if len(unip[0]) >= 1 or len(unip[1]) >= 1:\n",
      "            #iterate over combinations of both:\n",
      "            for i in itertools.product(unip[0],unip[1]):\n",
      "                EntIDstrings.append(i)\n",
      "    except KeyError:\n",
      "        faildictEnt[k] = l\n",
      "print \"Failed to map %i of %i entries.\"%(len(faildictEnt.values()), len(uniIDstrings))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Failed to map 241 of 4977 entries.\n"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which produces the list of interacting pairs in Entrez format.\n",
      "Some example entries can be shown:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print EntIDstrings[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('5894', '596'), ('596', '7157'), ('2033', '7157'), ('2118', '2033'), ('1385', '1387'), ('4603', '1387'), ('2033', '7528'), ('6720', '1387'), ('101839559', '6929'), ('4654', '6929')]\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Saving the lists\n",
      "\n",
      "There are many files we wish to make from this processed data.\n",
      "The naming scheme for these files is given below:\n",
      "\n",
      "* List of flattened gene identifiers:\n",
      "    * DIP IDs - `flat.DIP.txt`\n",
      "    * Uniprot IDs - `flat.uniprot.txt`\n",
      "    * Entrez IDs - `flat.Entrez.txt`\n",
      "* Lists of interacting pairs:\n",
      "    * DIP - `interacting.DIP.csv`\n",
      "    * Uniprot - `interacting.uniprot.csv`\n",
      "    * Entrez - `interacting.Entrez.cvs`\n",
      "    \n",
      "It's also important that the entries which failed to map are removed from the previous identifier's list, to make all lists compatible.\n",
      "This can be achieved easily using the `faildict` variables defined above:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use indexes in faildict to zero entries we're not interested in\n",
      "for k in faildict.keys():\n",
      "    IDstrings[k] = 0\n",
      "#the use ifilter to remove these entries\n",
      "IDstrings = list(itertools.ifilter(lambda x: x!=0, IDstrings))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#then do the same for uniIDstrings\n",
      "for k in faildictEnt.keys():\n",
      "    uniIDstrings[k] = 0\n",
      "uniIDstrings = list(itertools.ifilter(lambda x: x!=0, uniIDstrings))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#redefine the flattened list of uniprot IDs\n",
      "flatuniprot = list(unitoEnt.keys())\n",
      "#remove elements from flattened DIP IDs that don't map to Entrez\n",
      "flatIDstrings = [x for x in DIPtouni.keys() if all([a in flatuniprot for a in DIPtouni[x]])]\n",
      "#regenerate flat files:\n",
      "csv.writer(open(\"flat.DIP.txt\", \"w\"), delimiter=\"\\n\").writerow(flatIDstrings)\n",
      "csv.writer(open(\"flat.uniprot.txt\", \"w\"), delimiter=\"\\n\").writerow(flatuniprot)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#then save the flattened Entrez IDs\n",
      "flatEnt = list(flatten(unitoEnt.values()))\n",
      "csv.writer(open(\"flat.Entrez.txt\", \"w\"), delimiter=\"\\n\").writerow(flatEnt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#then save all of the interaction tables\n",
      "csv.writer(open(\"interacting.DIP.txt\", \"w\"), delimiter=\"\\t\").writerows(IDstrings)\n",
      "csv.writer(open(\"interacting.uniprot.txt\", \"w\"), delimiter=\"\\t\").writerows(uniIDstrings)\n",
      "csv.writer(open(\"interacting.Entrez.txt\", \"w\"), delimiter=\"\\t\").writerows(EntIDstrings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 195
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Checking crossover with Bait and Prey\n",
      "\n",
      "At this point it seems worthwhile to check if there are Bait or Prey proteins in our experimental results which are represented in this list of interacting proteins.\n",
      "As this is our ground truth which will be used to train our prediction algorithm any interactions present in the DIP dataset must be treated as real.\n",
      "In other words, our prediction algorithm can't outperform the training set.\n",
      "\n",
      "Loading in the bait and prey lists and combining them:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/forGAVIN/pulldown_data/PREYS/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/forGAVIN/pulldown_data/PREYS\n"
       ]
      }
     ],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[40m\u001b[m\u001b[00mensembl_prey_human_ids.csv\u001b[0m  \u001b[40m\u001b[m\u001b[00mprey_entrez_ids.csv\u001b[0m  \u001b[40m\u001b[m\u001b[00mpreys.csv\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "head prey_entrez_ids.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "53616\n",
        "8745\n",
        "161\n",
        "163\n",
        "1173\n",
        "375\n",
        "100500810\n",
        "10093\n",
        "477\n",
        "481\n"
       ]
      }
     ],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preyids = list(flatten(csv.reader(open(\"prey_entrez_ids.csv\"))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/forGAVIN/pulldown_data/BAITS/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/forGAVIN/pulldown_data/BAITS\n"
       ]
      }
     ],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[40m\u001b[m\u001b[00mbaits.csv\u001b[0m  \u001b[40m\u001b[m\u001b[00mbaits_entrez_ids_ActiveZone.csv\u001b[0m  \u001b[40m\u001b[m\u001b[00mbaits_entrez_ids.csv\u001b[0m  \u001b[40m\u001b[m\u001b[00mensembl_bait_human_ids.csv\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baitids = list(flatten(csv.reader(open(\"baits_entrez_ids.csv\"))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 211
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#check the crossover\n",
      "crossover = [x for x in baitids+preyids if x in flatEnt]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"%i of %i Entrez IDs in bait and prey lists are found in DIP dataset\"%(len(crossover),len(baitids+preyids))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "493 of 1933 Entrez IDs in bait and prey lists are found in DIP dataset\n"
       ]
      }
     ],
     "prompt_number": 214
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So about a quarter of the proteins we're interested in are found in the DIP dataset.\n",
      "However, this doesn't mean that a quarter of the interactions we're trying to find are already solved for.\n",
      "There could be interactions between any of these crossover proteins that are not accounted for in the DIP dataset."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}