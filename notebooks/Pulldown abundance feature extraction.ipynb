{
 "metadata": {
  "name": "",
  "signature": "sha256:e0bed5c93140e672e55c60cb0ba444ddc789bcbfc60a2a8c78627c5c183eb443"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The abundances reported by a [purification affinity experiment][promega] can be used to infer if two proteins interact.\n",
      "This data takes the form of an abundance measured across a number of experiments for every protein involved in the experiment.\n",
      "If a protein is abundant it is [more likely to interact][ivanic_influence_2009] with other proteins.\n",
      "\n",
      "__How was this abundance value calculated?__ Have to ask about this, I was just supplied it.\n",
      "\n",
      "Anyway, the table after processing will take the form:\n",
      "\n",
      "| Protein A | Protein B | Abundance | interacting |\n",
      "| --------- | --------- | --------- | ----------- |\n",
      "| 1234      | 4312      | 342.1     |     1       |\n",
      "| ...       | ...       | ...       |     ...     |\n",
      "\n",
      "With missing values treated as they were treated for the [affinity feature extraction][affinitynotebook].\n",
      "\n",
      "## Opening the files\n",
      "\n",
      "The first step is to open the necessary files.\n",
      "These include:\n",
      "\n",
      "* The training and test set protein pair lists\n",
      "* The pulldown abundance table\n",
      "\n",
      "[promega]: http://www.promega.com/~/media/files/resources/product%20guides/protein%20interaction/chap3.pdf?la=en\n",
      "[ivanic_influence_2009]: http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0005815\n",
      "[affinitynotebook]: http://nbviewer.ipython.org/github/ggray1729/opencast-bio/blob/master/notebooks/Pulldown%20affinity%20feature%20extraction.ipynb"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/forGAVIN/pulldown_data/dataset/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/forGAVIN/pulldown_data/dataset\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[40m\u001b[m\u001b[00mppi_ab_entrez.csv\u001b[0m  \u001b[40m\u001b[m\u001b[00mppi_entrez.csv\u001b[0m  \u001b[40m\u001b[m\u001b[00mppi_interactions_ab.csv\u001b[0m  \u001b[40m\u001b[m\u001b[00mppi_interactions.csv\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#first the pulldown abundance table\n",
      "ppiab = list(csv.reader(open(\"ppi_ab_entrez.csv\"), delimiter=\"\\t\"))\n",
      "#discard first line\n",
      "ppiab = ppiab[1:]\n",
      "# protein pair to frozenset\n",
      "ppiab = map(lambda x: (frozenset([x[0],x[1]]),x[2]), ppiab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/DIP/human/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/DIP/human\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[40m\u001b[m\u001b[00mDIPtouniprot.tab\u001b[0m  \u001b[40m\u001b[m\u001b[00mflat.Entrez.txt\u001b[0m   \u001b[40m\u001b[m\u001b[00mHsapi20140427.txt\u001b[0m    \u001b[40m\u001b[m\u001b[00minteracting.Entrez.txt\u001b[0m   \u001b[40m\u001b[m\u001b[00mtraining.negative.Entrez.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00muniprottoEntrez.tab\u001b[0m\r\n",
        "\u001b[40m\u001b[m\u001b[00mflat.DIP.txt\u001b[0m      \u001b[40m\u001b[m\u001b[00mflat.uniprot.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00minteracting.DIP.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00minteracting.uniprot.txt\u001b[0m  \u001b[40m\u001b[m\u001b[00mtraining.positive.Entrez.txt\u001b[0m\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#second the training and test set protein pairs\n",
      "posids = list(csv.reader(open(\"training.positive.Entrez.txt\"), delimiter=\"\\t\"))\n",
      "negids = list(csv.reader(open(\"training.negative.Entrez.txt\"), delimiter=\"\\t\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/gavin/Documents/MRes/features/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/Documents/MRes/features\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# building the dictionary:\n",
      "traintestdict = {}\n",
      "for line in posids+negids:\n",
      "    traintestdict[frozenset([line[0],line[1]])] = line[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create a dictionary using frozensets from ppiab as keys\n",
      "ppiabdict = {}\n",
      "for line in ppiab:\n",
      "    ppiabdict[line[0]] = line[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Saving the features\n",
      "\n",
      "This will be done in the same way as with the [affinity features][affinitynotebook].\n",
      "There will be two files:\n",
      "\n",
      "1. abundance.Entrez.full.txt - includes all protein pairs, with \"missing\" placeholders for unknown pairs.\n",
      "2. abundance.Entrez.traintest.txt - includes only protein pairs the training and test sets knows of.\n",
      "\n",
      "Both will be of the form defined above:\n",
      "\n",
      "[affinitynotebook]: http://nbviewer.ipython.org/github/ggray1729/opencast-bio/blob/master/notebooks/Pulldown%20affinity%20feature%20extraction.ipynb"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#write the resulting table to a file\n",
      "cfull = csv.writer(open(\"abundance.Entrez.full.txt\",\"w\"), delimiter=\"\\t\")\n",
      "ctraintest = csv.writer(open(\"abundance.Entrez.traintest.txt\",\"w\"), delimiter=\"\\t\")\n",
      "#iterate over the keys\n",
      "for key in ppiabdict.keys():\n",
      "    pair = list(key)\n",
      "    try:\n",
      "        #index both dictionaries to build a row in the file\n",
      "        row = [pair[0],pair[1],ppiabdict[key],traintestdict[key]]\n",
      "        #write this row to the file\n",
      "        cfull.writerow(row)\n",
      "        ctraintest.writerow(row)\n",
      "    except KeyError:\n",
      "        #failed to find a training set entry for this value \n",
      "        #print \"missing\" to indicate this\n",
      "        row = [pair[0],pair[1], ppiabdict[key], \"missing\"]\n",
      "        cfull.writerow(row)\n",
      "    except IndexError:\n",
      "        #ignore self-interactions\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Coverage\n",
      "\n",
      "We can check the coverage by simply looking at the files we've just created."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "wc -l abundance.Entrez.full.txt\n",
      "wc -l abundance.Entrez.traintest.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15909 abundance.Entrez.full.txt\n",
        "378 abundance.Entrez.traintest.txt\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which is an extremely low number, much smaller than expected.\n",
      "It should be similar, or exactly the same as the numbers for the affinity feature.\n",
      "The coverage on the training and test set is going to be extremely low:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"The coverage of the abundance feature on the training and test set is %.2f\"%(100.0*(378.0/len(traintestdict.keys()))) + \"%\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The coverage of the abundance feature on the training and test set is 0.01%\n"
       ]
      }
     ],
     "prompt_number": 14
    }
   ],
   "metadata": {}
  }
 ]
}